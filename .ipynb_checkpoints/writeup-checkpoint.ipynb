{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Behavioral Cloning** \n",
    "\n",
    "---\n",
    "\n",
    "### Project Description\n",
    "\n",
    "The aim of this project is to showcase the power of deep neural networks into mimicing some specific behavior and reproducing it for a given task. In our case, it's driving a car into the road. The data provided in this project consist of images coming from cameras mounted on the car (front, front left, front right) and the steering angles of the vehicle. All of this, taking place into the Udacity's simulator.\n",
    "\n",
    "My pipeline is described as below:\n",
    "\n",
    "- Data preprocessing\n",
    "- Data augmentation \n",
    "- Model design and architecture\n",
    "- Model training and deployment\n",
    "\n",
    "### Files included\n",
    "\n",
    "`model.py` : Building and training the model .<br>\n",
    "`drive.py` : Driving the car in the simulator after training.<br>\n",
    "`model.h5` : Model weights.<br>\n",
    "`output_video.mp4` : The output video of testing the model in the simulator.\n",
    "\n",
    "### Data preprocessing\n",
    "\n",
    "My training data consists of 8036 samples. Each sample contains 3 images (left, center, right) taken at the same time and their corresponding steering value ranging from -1 to 1. So I'm having a 8036x3 = 24108 images with repeating steering values for left, right and center images taken at the same time, which results a 24108 sample images.\n",
    "\n",
    "### Data augmentation\n",
    "\n",
    "In order to augment my data and give my neural network a better idea on what's going on. I flipped the images on the vertical axis and multiplied their corresponding steering values by -1 so that the model don't overfit on the left turn only but also on the right turns.\n",
    "\n",
    "### Model architecture\n",
    "\n",
    "The architecture I built was inspired by the [NVIDIA model](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) that have been used in their End-to-End Deep Learning for Self-Driving Cars project. My architecture named DriveNet is described as follows:\n",
    "\n",
    "|Layer\t\t\t\t\t|Description\t\t\t\t\t\t\t\t\t|Activation\t\t\t\t\t\t\t\t\t\t| Shape\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:|:---------------------------------------------:| :----------------:| \n",
    "|Input\t\t\t\t\t| RGB image\t\t\t\t\t\t\t\t\t\t|-\t\t\t\t\t\t\t\t\t\t\t\t| (160x320x3)\t\t| \n",
    "|Lambda\t\t\t\t\t| Normalization Layer to help the network converge fastly|-\t\t\t\t\t\t\t\t\t\t| (160x320x3)\t\t|\n",
    "|Cropping\t\t\t\t| Cropping out region of less interest (sky, ...)|-\t\t\t\t\t\t\t\t\t\t\t\t| (65x320x3)\t\t|\n",
    "|Conv24\t\t\t\t\t| 5x5 filter, 2x2 strides\t\t\t\t\t\t|ReLU\t\t\t\t\t\t\t\t\t\t\t| (31x158x24)\t\t| \n",
    "|Conv36\t\t\t\t\t| 5x5 filter, 2x2 strides\t\t\t\t\t\t|ReLU\t\t\t\t\t\t\t\t\t\t\t| (14x77x36)\t\t|\n",
    "|Conv48\t\t\t\t\t| 5x5 filter, 2x2 strides\t\t\t\t\t\t|ReLU\t\t\t\t\t\t\t\t\t\t\t| (5x37x48)\t\t\t|\n",
    "|Conv64\t\t\t\t\t| 3x3 filter, 1x1 strides\t\t\t\t\t\t|ReLU\t\t\t\t\t\t\t\t\t\t\t| (3x35x64)\t\t\t|\n",
    "|Conv64\t\t\t\t\t| 3x3 filter, 1x1 strides\t\t\t\t\t\t|ReLU\t\t\t\t\t\t\t\t\t\t\t| (1x33x64)\t\t\t|\n",
    "|Flatten\t\t\t\t| Flattening into one-dimensional array\t\t\t|-\t\t\t\t\t\t\t\t\t\t\t\t| (2112)\t\t\t|\n",
    "|Dropout\t\t\t\t| 50% of dropout to avoid overfitting on the feature vector\t\t\t|-\t\t\t\t\t\t\t| (2112)\t\t\t|\n",
    "|Dense100\t\t\t\t| Fully connected layer of 100 neurons\t\t\t|Linear\t\t\t\t\t\t\t\t\t\t\t| (100)\t\t\t\t|\n",
    "|Dropout\t\t\t\t| 50% of dropout\t\t\t\t\t\t\t\t|-\t\t\t\t\t\t\t\t\t\t\t\t| (100)\t\t\t\t|\n",
    "|Dense10\t\t\t\t| Fully connected layer of 10 neurons\t\t\t|Linear\t\t\t\t\t\t\t\t\t\t\t| (10)\t\t\t\t|\n",
    "|Output\t\t\t\t\t| Output layer\t\t\t\t\t\t\t\t\t|Linear\t\t\t\t\t\t\t\t\t\t\t| (1)\t\t\t\t|\n",
    "\n",
    "<center>Trainable parameters: 348,219</center>\n",
    "<br>\n",
    "\n",
    "I included in my model some preprocessing like the normlization and cropping of the images. The ReLU activation was doing good introducting non-linearity into the model. The dropout was also helpfull making me avoid overfitting.\n",
    "\n",
    "### Model training\n",
    "\n",
    "I chose to optimize the mean square error loss function using `Adam` optimizer with a constant learning rate of 5e-3.  I split and shuffled  my data using 20% of it for validation. I trained my model only on the training data for 7 Epochs using a batch size of 64. \n",
    "\n",
    "### Model testing and deployment\n",
    "\n",
    "I tested my model on the udacity simulator it was driving very good. So I wanted to push my testing further to evaluate model robustness. What I did is that I edited the `drive.py` file, I increased the speed of the PI throttle controller from 9 MPH to 30 MPH so if the model isn't stable enough certainly it will fail at some point in the circuit like by the bride or the turns right after it. But my model has resisted all of this and still worked fine. I'm very proud of this achievement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
